{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "308bbfb7-4cda-4bb4-b007-d253d1a8a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- --------------------\n",
      "absl-py                            1.4.0\n",
      "accelerate                         0.25.0\n",
      "aiofiles                           23.2.1\n",
      "aiohttp-cors                       0.7.0\n",
      "altair                             5.2.0\n",
      "annotated-types                    0.6.0\n",
      "anyio                              3.7.1\n",
      "arrow                              1.3.0\n",
      "asn1crypto                         1.5.1\n",
      "asttokens                          2.0.5\n",
      "astunparse                         1.6.3\n",
      "attrs                              23.1.0\n",
      "backcall                           0.2.0\n",
      "blessed                            1.20.0\n",
      "blis                               0.7.11\n",
      "Bottleneck                         1.3.5\n",
      "brotlipy                           0.7.0\n",
      "cachetools                         5.3.2\n",
      "catalogue                          2.0.10\n",
      "certifi                            2023.7.22\n",
      "cffi                               1.16.0\n",
      "chardet                            5.1.0\n",
      "charset-normalizer                 3.1.0\n",
      "click                              8.1.7\n",
      "cloudpathlib                       0.16.0\n",
      "cloudpickle                        3.0.0\n",
      "codecarbon                         2.3.2\n",
      "colorama                           0.4.6\n",
      "colorful                           0.5.5\n",
      "comm                               0.1.2\n",
      "conda                              23.3.1\n",
      "conda-package-handling             2.0.2\n",
      "conda_package_streaming            0.8.0\n",
      "confection                         0.1.4\n",
      "contextlib2                        21.6.0\n",
      "contourpy                          1.0.5\n",
      "cryptography                       41.0.1\n",
      "cycler                             0.11.0\n",
      "cymem                              2.0.8\n",
      "Cython                             0.29.35\n",
      "daal                               2024.0.1\n",
      "daal4py                            2024.0.1\n",
      "debugpy                            1.6.7\n",
      "decorator                          5.1.1\n",
      "Deprecated                         1.2.14\n",
      "distlib                            0.3.7\n",
      "dpcpp-llvm-spirv                   0.0.0\n",
      "dpctl                              0.14.4+27.ga3cde67f7\n",
      "dpnp                               0.12.0\n",
      "einops                             0.7.0\n",
      "en-core-web-sm                     3.7.1\n",
      "exceptiongroup                     1.0.4\n",
      "executing                          0.8.3\n",
      "Faker                              21.0.0\n",
      "fastapi                            0.105.0\n",
      "ffmpy                              0.3.1\n",
      "filelock                           3.13.1\n",
      "flatbuffers                        23.5.26\n",
      "fonttools                          4.25.0\n",
      "fsspec                             2023.12.0\n",
      "funcsigs                           1.0.2\n",
      "future                             0.18.3\n",
      "fuzzywuzzy                         0.18.0\n",
      "gast                               0.5.4\n",
      "google-api-core                    2.14.0\n",
      "google-auth                        2.24.0\n",
      "google-auth-oauthlib               1.0.0\n",
      "google-pasta                       0.2.0\n",
      "googleapis-common-protos           1.61.0\n",
      "gpustat                            1.1.1\n",
      "gradio                             4.9.1\n",
      "gradio_client                      0.7.3\n",
      "grpcio                             1.59.3\n",
      "h11                                0.14.0\n",
      "h5py                               3.10.0\n",
      "httpcore                           1.0.2\n",
      "httpx                              0.25.2\n",
      "huggingface-hub                    0.17.3\n",
      "idna                               3.4\n",
      "importlib-metadata                 6.0.0\n",
      "importlib-resources                6.1.1\n",
      "intel-extension-for-pytorch        2.0.120+xpu\n",
      "intel-extension-for-tensorflow     2.14.0.1\n",
      "intel-extension-for-tensorflow-lib 2.14.0.1.2\n",
      "intel-extension-for-transformers   1.2.2\n",
      "intel-optimization-for-horovod     0.28.1.1\n",
      "invisible-watermark                0.2.0\n",
      "ipykernel                          6.25.0\n",
      "ipython                            8.15.0\n",
      "ipywidgets                         8.0.4\n",
      "jedi                               0.18.1\n",
      "Jinja2                             3.1.2\n",
      "joblib                             1.2.0\n",
      "jsonpatch                          1.32\n",
      "jsonpointer                        2.0\n",
      "jsonschema                         4.20.0\n",
      "jsonschema-specifications          2023.11.2\n",
      "jupyter_client                     8.1.0\n",
      "jupyter_core                       5.3.0\n",
      "jupyterlab-widgets                 3.0.5\n",
      "keras                              2.14.0\n",
      "kiwisolver                         1.4.4\n",
      "langcodes                          3.3.0\n",
      "libarchive-c                       4.0\n",
      "libclang                           16.0.6\n",
      "llvmlite                           0.40.0\n",
      "Markdown                           3.5.1\n",
      "markdown-it-py                     3.0.0\n",
      "MarkupSafe                         2.1.3\n",
      "matplotlib                         3.6.2\n",
      "matplotlib-inline                  0.1.6\n",
      "mdurl                              0.1.2\n",
      "mkl-fft                            1.3.6\n",
      "mkl-random                         1.2.2\n",
      "mkl-service                        2.4.0\n",
      "mkl-umath                          0.1.1\n",
      "ml-dtypes                          0.2.0\n",
      "modin                              0.25.1\n",
      "mpmath                             1.3.0\n",
      "msgpack                            1.0.7\n",
      "munkres                            1.1.4\n",
      "murmurhash                         1.0.10\n",
      "nest-asyncio                       1.5.6\n",
      "networkx                           3.2.1\n",
      "neural-compressor                  2.3.2\n",
      "numba                              0.57.0\n",
      "numba-dpex                         0.21.0\n",
      "numexpr                            2.8.7\n",
      "numpy                              1.24.3\n",
      "nvidia-cublas-cu12                 12.2.5.6\n",
      "nvidia-cuda-cupti-cu12             12.2.142\n",
      "nvidia-cuda-nvcc-cu12              12.2.140\n",
      "nvidia-cuda-nvrtc-cu12             12.2.140\n",
      "nvidia-cuda-runtime-cu12           12.2.140\n",
      "nvidia-cudnn-cu12                  8.9.4.25\n",
      "nvidia-cufft-cu12                  11.0.8.103\n",
      "nvidia-curand-cu12                 10.3.3.141\n",
      "nvidia-cusolver-cu12               11.5.2.141\n",
      "nvidia-cusparse-cu12               12.1.2.141\n",
      "nvidia-ml-py                       12.535.133\n",
      "nvidia-nccl-cu12                   2.16.5\n",
      "nvidia-nvjitlink-cu12              12.2.140\n",
      "oauthlib                           3.2.2\n",
      "oneccl-bind-pt                     2.0.200+gpu\n",
      "opencensus                         0.11.3\n",
      "opencensus-context                 0.1.3\n",
      "opencv-python                      4.8.1.78\n",
      "opencv-python-headless             4.8.1.78\n",
      "opt-einsum                         3.3.0\n",
      "orjson                             3.9.10\n",
      "packaging                          23.1\n",
      "pandas                             2.1.3\n",
      "parso                              0.8.3\n",
      "pexpect                            4.8.0\n",
      "pickleshare                        0.7.5\n",
      "Pillow                             10.0.0\n",
      "pip                                23.1.2\n",
      "platformdirs                       3.6.0\n",
      "pluggy                             1.0.0\n",
      "pooch                              1.7.0\n",
      "preshed                            3.0.9\n",
      "prettytable                        3.9.0\n",
      "prometheus-client                  0.19.0\n",
      "prompt-toolkit                     3.0.36\n",
      "protobuf                           4.23.4\n",
      "psutil                             5.9.0\n",
      "ptyprocess                         0.7.0\n",
      "pure-eval                          0.2.2\n",
      "py-cpuinfo                         9.0.0\n",
      "py-spy                             0.3.14\n",
      "pyarrow                            14.0.1\n",
      "pyasn1                             0.5.1\n",
      "pyasn1-modules                     0.3.0\n",
      "pycocotools                        2.0.7\n",
      "pycosat                            0.6.4\n",
      "pycparser                          2.21\n",
      "pydantic                           2.5.2\n",
      "pydantic_core                      2.14.5\n",
      "pydub                              0.25.1\n",
      "pyeditline                         2.0.1\n",
      "Pygments                           2.15.1\n",
      "pynvml                             11.5.0\n",
      "pyOpenSSL                          23.2.0\n",
      "pyparsing                          3.1.0\n",
      "PySocks                            1.7.1\n",
      "python-dateutil                    2.8.2\n",
      "python-multipart                   0.0.6\n",
      "pytz                               2023.3\n",
      "PyWavelets                         1.5.0\n",
      "PyYAML                             6.0\n",
      "pyzmq                              25.1.0\n",
      "ray                                2.8.1\n",
      "referencing                        0.31.1\n",
      "regex                              2023.10.3\n",
      "requests                           2.31.0\n",
      "requests-oauthlib                  1.3.1\n",
      "rich                               13.7.0\n",
      "rpds-py                            0.13.2\n",
      "rsa                                4.9\n",
      "ruamel.yaml                        0.17.32\n",
      "ruamel.yaml.clib                   0.2.7\n",
      "safetensors                        0.4.1\n",
      "schema                             0.7.5\n",
      "scikit-learn                       1.2.2\n",
      "scikit-learn-intelex               2024.0.1\n",
      "scipy                              1.10.1\n",
      "seaborn                            0.12.2\n",
      "semantic-version                   2.10.0\n",
      "sentencepiece                      0.1.99\n",
      "setuptools                         67.7.2\n",
      "shellingham                        1.5.4\n",
      "six                                1.16.0\n",
      "smart-open                         6.4.0\n",
      "SMP                                0.1.4\n",
      "sniffio                            1.3.0\n",
      "spacy                              3.7.2\n",
      "spacy-legacy                       3.0.12\n",
      "spacy-loggers                      1.0.5\n",
      "srsly                              2.4.8\n",
      "stack-data                         0.2.0\n",
      "starlette                          0.27.0\n",
      "sympy                              1.12\n",
      "tbb                                2021.11.0\n",
      "tensorboard                        2.14.1\n",
      "tensorboard-data-server            0.7.2\n",
      "tensorflow                         2.14.1\n",
      "tensorflow-estimator               2.14.0\n",
      "tensorflow-io-gcs-filesystem       0.34.0\n",
      "tensorrt                           8.6.1.post1\n",
      "tensorrt-bindings                  8.6.1\n",
      "tensorrt-libs                      8.6.1\n",
      "termcolor                          2.4.0\n",
      "thinc                              8.2.2\n",
      "threadpoolctl                      3.1.0\n",
      "tokenizers                         0.14.1\n",
      "tomlkit                            0.12.0\n",
      "toolz                              0.12.0\n",
      "torch                              2.0.1a0+cxx11.abi\n",
      "torchvision                        0.15.2a0+cxx11.abi\n",
      "tornado                            6.3.2\n",
      "tqdm                               4.66.1\n",
      "traitlets                          5.7.1\n",
      "transformers                       4.34.1\n",
      "typer                              0.9.0\n",
      "types-python-dateutil              2.8.19.14\n",
      "typing_extensions                  4.9.0\n",
      "tzdata                             2023.3\n",
      "urllib3                            2.0.3\n",
      "uvicorn                            0.24.0.post1\n",
      "virtualenv                         20.21.0\n",
      "wasabi                             1.1.2\n",
      "wcwidth                            0.2.5\n",
      "weasel                             0.3.4\n",
      "websockets                         11.0.3\n",
      "Werkzeug                           3.0.1\n",
      "wheel                              0.40.0\n",
      "widgetsnbextension                 4.0.5\n",
      "wrapt                              1.14.1\n",
      "xgboost                            2.0.2\n",
      "zipp                               3.11.0\n",
      "zstandard                          0.19.0\n"
     ]
    }
   ],
   "source": [
    "# !python -m pip install --upgrade intel-extension-for-tensorflow[xpu]\n",
    "# !pip freeze > requirements.txt\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3941040da39a488b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T09:30:39.137105Z",
     "start_time": "2023-12-15T09:30:32.096263Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn-intelex Faker spacy ipywidgets\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# ignore all warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c7d3b17c0186a7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class Product:\n",
    "    def __init__(self, id, name, category = 'Electronics', price = 100, quantity = 10, color = None, size = None, rating = None, manufacturer = None, availability = None, description = None):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.category = category\n",
    "        self.price = price\n",
    "        self.quantity = quantity\n",
    "        self.color = color\n",
    "        self.size = size\n",
    "        self.rating = rating\n",
    "        self.manufacturer = manufacturer\n",
    "        self.availability = availability\n",
    "        self.description = description\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps(self)\n",
    "\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n",
    "\n",
    "\n",
    "class Store:\n",
    "    def __init__(self):\n",
    "        self.products = {}\n",
    "\n",
    "    def add_product(self, product):\n",
    "        self.products[product.id] = product\n",
    "\n",
    "    def update_product(self, product_id, **kwargs):\n",
    "        if product_id in self.products:\n",
    "            for key, value in kwargs.items():\n",
    "                setattr(self.products[product_id], key, value)\n",
    "        else:\n",
    "            print(f\"Product with id {product_id} not found.\")\n",
    "\n",
    "    def update_availability(self, product_id, new_availability):\n",
    "        if product_id in self.products:\n",
    "            self.products[product_id].availability = new_availability\n",
    "            print(f\"Product ID {product_id} availability updated to {new_availability}.\")\n",
    "        else:\n",
    "            print(f\"Product with ID {product_id} not found.\")\n",
    "\n",
    "    def get_product(self, id):\n",
    "        return self.products.get(id, None)\n",
    "\n",
    "    def display_products(self):\n",
    "        for product in self.products.values():\n",
    "            print(product.to_json())\n",
    "\n",
    "    def display_products_by_category(self, category):\n",
    "        found = False\n",
    "        for product in self.products.values():\n",
    "            if product.category.lower() == category.lower():\n",
    "                print(product.to_json())\n",
    "                found = True\n",
    "        if not found:\n",
    "            print(f\"No products found in category: {category}\")\n",
    "\n",
    "    def update_products_by_category(self, category, new_availability):\n",
    "        found = False\n",
    "        for product in self.products.values():\n",
    "            if product.category.lower() == category.lower():\n",
    "                product.availability = new_availability\n",
    "                print(f\"Updated {product.name} to {'available' if new_availability else 'unavailable'}\")\n",
    "                found = True\n",
    "        if not found:\n",
    "            print(f\"No products found in category: {category}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93834d378f41d32d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Function to generate and add products to the store\n",
    "def generate_products(store, n, categories):\n",
    "    fake = Faker()\n",
    "    for _ in range(n):\n",
    "        id = fake.unique.uuid4()\n",
    "        name = f\"{fake.word().capitalize()} {fake.random_element(elements=('Pro', 'Max', 'Plus'))}\"\n",
    "        category = random.choice(categories)\n",
    "        price = round(random.uniform(10, 1000), 2)\n",
    "        quantity = random.randint(1, 100)\n",
    "        color = fake.color_name()\n",
    "        size = random.choice(['Small', 'Medium', 'Large'])\n",
    "        rating = round(random.uniform(1, 5), 1)\n",
    "        manufacturer = fake.company()\n",
    "        availability = random.choice([True, False])\n",
    "        description = fake.text()\n",
    "\n",
    "        product = Product(id, name, category, price, quantity, color, size, rating, manufacturer, availability, description)\n",
    "        store.add_product(product)\n",
    "\n",
    "# Create a store instance\n",
    "store = Store()\n",
    "\n",
    "# Define the number of products and categories\n",
    "num_products = 10\n",
    "categories = ['Electronics', 'Clothing', 'Home & Kitchen']\n",
    "\n",
    "# Generate products and add them to the store\n",
    "generate_products(store, num_products, categories)\n",
    "\n",
    "# Display products in the store\n",
    "# store.display_products()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a2827a0385e3b5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"availability\": true,\n",
      "    \"category\": \"Clothing\",\n",
      "    \"color\": \"DimGray\",\n",
      "    \"description\": \"Sister fill sell parent. Require group treat describe certainly budget animal. Lay person thus price. Type leader box shoulder share.\\nEnvironmental various either.\",\n",
      "    \"id\": \"4401d68e-4689-4ce6-9715-97c310bde972\",\n",
      "    \"manufacturer\": \"Powell Ltd\",\n",
      "    \"name\": \"Maintain Plus\",\n",
      "    \"price\": 273.44,\n",
      "    \"quantity\": 33,\n",
      "    \"rating\": 4.6,\n",
      "    \"size\": \"Medium\"\n",
      "}\n",
      "Product with ID 4401d68e-4689-4ce6-9715-97c310bde972 updated.\n",
      "{\n",
      "    \"availability\": true,\n",
      "    \"category\": \"Clothing\",\n",
      "    \"color\": \"DimGray\",\n",
      "    \"description\": \"Sister fill sell parent. Require group treat describe certainly budget animal. Lay person thus price. Type leader box shoulder share.\\nEnvironmental various either.\",\n",
      "    \"id\": \"4401d68e-4689-4ce6-9715-97c310bde972\",\n",
      "    \"manufacturer\": \"Powell Ltd\",\n",
      "    \"name\": \"Maintain Plus\",\n",
      "    \"price\": 0,\n",
      "    \"quantity\": 33,\n",
      "    \"rating\": 4.6,\n",
      "    \"size\": \"Medium\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Function to find and update a product in the store\n",
    "def find_and_update_product(store, product_id, **update_attrs):\n",
    "    # Check if the product exists in the store\n",
    "    if product_id in store.products:\n",
    "        # Update the product attributes\n",
    "        store.update_product(product_id, **update_attrs)\n",
    "        print(f\"Product with ID {product_id} updated.\")\n",
    "        # Display the updated product details\n",
    "        print(store.get_product(product_id).to_json())\n",
    "    else:\n",
    "        print(f\"Product with ID {product_id} not found.\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a product ID (you can get one from the existing products in the store)\n",
    "sample_product_id = list(store.products.keys())[0]  # Get the ID of the first product in the store\n",
    "print(store.get_product(sample_product_id).to_json())\n",
    "# Update the product (for example, change its price and availability)\n",
    "find_and_update_product(store, sample_product_id, price=0, availability=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50704a5f02caecb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID 4401d68e-4689-4ce6-9715-97c310bde972 availability updated to False.\n",
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Clothing\",\n",
      "    \"color\": \"DimGray\",\n",
      "    \"description\": \"Sister fill sell parent. Require group treat describe certainly budget animal. Lay person thus price. Type leader box shoulder share.\\nEnvironmental various either.\",\n",
      "    \"id\": \"4401d68e-4689-4ce6-9715-97c310bde972\",\n",
      "    \"manufacturer\": \"Powell Ltd\",\n",
      "    \"name\": \"Maintain Plus\",\n",
      "    \"price\": 0,\n",
      "    \"quantity\": 33,\n",
      "    \"rating\": 4.6,\n",
      "    \"size\": \"Medium\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example usage to update availability:\n",
    "sample_product_id = list(store.products.keys())[0]  # Get the ID of the first product\n",
    "store.update_availability(sample_product_id, False)  # Update availability to False\n",
    "\n",
    "# Display the updated product details\n",
    "print(store.get_product(sample_product_id).to_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65272809912fa68d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Clothing\",\n",
      "    \"color\": \"DimGray\",\n",
      "    \"description\": \"New description\",\n",
      "    \"id\": \"4401d68e-4689-4ce6-9715-97c310bde972\",\n",
      "    \"manufacturer\": \"Powell Ltd\",\n",
      "    \"name\": \"New Product Name\",\n",
      "    \"price\": 299.99,\n",
      "    \"quantity\": 33,\n",
      "    \"rating\": 4.6,\n",
      "    \"size\": \"Medium\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example usage to update multiple product attributes:\n",
    "sample_product_id = list(store.products.keys())[0]  # Assume this is the product ID\n",
    "store.update_product(sample_product_id, name=\"New Product Name\", description=\"New description\", price=299.99)\n",
    "\n",
    "# Display the updated product\n",
    "print(store.get_product(sample_product_id).to_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf575def6a4c7d5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(store.get_product(sample_product_id).to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ccb7f333fffca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Assuming the Product and Store classes are defined as earlier\n",
    "\n",
    "def create_product():\n",
    "    fake = Faker()\n",
    "    id = fake.unique.uuid4()\n",
    "    name = f\"{fake.word().capitalize()} {fake.random_element(elements=('Pro', 'Max', 'Plus'))}\"\n",
    "    category = random.choice(['Electronics', 'Clothing', 'Home & Kitchen'])\n",
    "    price = round(random.uniform(10, 1000), 2)\n",
    "    quantity = random.randint(1, 100)\n",
    "    color = fake.color_name()\n",
    "    size = random.choice(['Small', 'Medium', 'Large'])\n",
    "    rating = round(random.uniform(1, 5), 1)\n",
    "    manufacturer = fake.company()\n",
    "    availability = random.choice([True, False])\n",
    "    description = fake.text()\n",
    "\n",
    "    return Product(id, name, category, price, quantity, color, size, rating, manufacturer, availability, description)\n",
    "\n",
    "# Create a store instance if not already created\n",
    "demo_store = Store()\n",
    "\n",
    "# Create a new product\n",
    "new_product = create_product()\n",
    "\n",
    "# Add the new product to the store\n",
    "demo_store.add_product(new_product)\n",
    "\n",
    "# Display the added product\n",
    "print(\"Added new product:\")\n",
    "print(new_product.to_json())\n",
    "\n",
    "# Optionally, display all products in the store\n",
    "print(\"\\nAll products in the store:\")\n",
    "demo_store.display_products()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b58cbaa5e80a8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Original store products\n",
    "# store.display_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa7b4452e811bab",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def find_product_by_attribute(store, **attributes):\n",
    "    for product in store.products.values():\n",
    "        if all(getattr(product, key, None) == value for key, value in attributes.items()):\n",
    "            return product\n",
    "    return None\n",
    "\n",
    "def update_product_by_attribute(store, search_attrs, **update_attrs):\n",
    "    product = find_product_by_attribute(store, **search_attrs)\n",
    "    if product:\n",
    "        product_id = product.id\n",
    "        store.update_product(product_id, **update_attrs)\n",
    "        print(f\"Product with attributes {search_attrs} updated.\")\n",
    "        print(product.to_json())\n",
    "    else:\n",
    "        print(f\"No product found with attributes {search_attrs}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc640b1731c3dcf1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Clothing\",\n",
      "    \"color\": \"DimGray\",\n",
      "    \"description\": \"New description\",\n",
      "    \"id\": \"4401d68e-4689-4ce6-9715-97c310bde972\",\n",
      "    \"manufacturer\": \"Powell Ltd\",\n",
      "    \"name\": \"New Product Name\",\n",
      "    \"price\": 299.99,\n",
      "    \"quantity\": 33,\n",
      "    \"rating\": 4.6,\n",
      "    \"size\": \"Medium\"\n",
      "}\n",
      "No product found with attributes {'color': 'DarkSalmon'}.\n"
     ]
    }
   ],
   "source": [
    "# Example: Find a product by name and update its price\n",
    "sample_product_id = list(store.products.keys())[0]\n",
    "sample_product = store.get_product(sample_product_id)\n",
    "print(sample_product.to_json())\n",
    "search_attributes = {'color': 'DarkSalmon'}\n",
    "update_attributes = {'price': 200.00}\n",
    "update_product_by_attribute(store, search_attributes, **update_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b2e84d89d995ab7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def update_all_matching_products(store, search_attrs, **update_attrs):\n",
    "    updated_products = []\n",
    "    for product_id, product in store.products.items():\n",
    "        if all(getattr(product, key, None) == value for key, value in search_attrs.items()):\n",
    "            store.update_product(product_id, **update_attrs)\n",
    "            updated_products.append(product_id)\n",
    "\n",
    "    if updated_products:\n",
    "        print(f\"Updated products with IDs: {updated_products}\")\n",
    "        for pid in updated_products:\n",
    "            print(store.get_product(pid).to_json())\n",
    "    else:\n",
    "        print(f\"No products found with attributes {search_attrs}.\")\n",
    "\n",
    "# Example: Update all products with a specific category to a new price\n",
    "# search_attributes = {'category': 'Electronics'}\n",
    "# update_attributes = {'price': 299.99}\n",
    "# update_all_matching_products(store, search_attributes, **update_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fcd0677-bcdd-45d7-9509-00f9e63d31c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             intent  \\\n",
      "0                 AddProductIntent1   \n",
      "1          UpdateProductByIdIntent2   \n",
      "2   UpdateProductByAttributeIntent3   \n",
      "3  UpdateAllMatchingProductsIntent4   \n",
      "4                FindProductIntent5   \n",
      "\n",
      "                                       sample_phrase  \n",
      "0           Add a new product named X with price $99  \n",
      "1       Change the price of product with ID X to $99  \n",
      "2  Update all products in category Electronics to...  \n",
      "3  Set all products from manufacturer X to price $99  \n",
      "4  Show me all products in the Home & Kitchen cat...  \n",
      "                              intent  \\\n",
      "0                  AddProductIntent1   \n",
      "1           UpdateProductByIdIntent2   \n",
      "2    UpdateProductByAttributeIntent3   \n",
      "3   UpdateAllMatchingProductsIntent4   \n",
      "4                 FindProductIntent5   \n",
      "5                  AddProductIntent1   \n",
      "6                  AddProductIntent1   \n",
      "7                  AddProductIntent1   \n",
      "8                  AddProductIntent1   \n",
      "9           UpdateProductByIdIntent2   \n",
      "10          UpdateProductByIdIntent2   \n",
      "11          UpdateProductByIdIntent2   \n",
      "12          UpdateProductByIdIntent2   \n",
      "13   UpdateProductByAttributeIntent3   \n",
      "14   UpdateProductByAttributeIntent3   \n",
      "15   UpdateProductByAttributeIntent3   \n",
      "16   UpdateProductByAttributeIntent3   \n",
      "17  UpdateAllMatchingProductsIntent4   \n",
      "18  UpdateAllMatchingProductsIntent4   \n",
      "19  UpdateAllMatchingProductsIntent4   \n",
      "20  UpdateAllMatchingProductsIntent4   \n",
      "21                FindProductIntent5   \n",
      "22                FindProductIntent5   \n",
      "23                FindProductIntent5   \n",
      "24                FindProductIntent5   \n",
      "\n",
      "                                        sample_phrase  \n",
      "0            Add a new product named X with price $99  \n",
      "1        Change the price of product with ID X to $99  \n",
      "2   Update all products in category Electronics to...  \n",
      "3   Set all products from manufacturer X to price $99  \n",
      "4   Show me all products in the Home & Kitchen cat...  \n",
      "5                  Insert a new item named Y for $150  \n",
      "6             Register product Z with a price of $200  \n",
      "7                     Include a new product W at $300  \n",
      "8                  List a new item Q for sale at $250  \n",
      "9             Alter the price of product ID Y to $150  \n",
      "10           Modify cost of product with ID Z to $200  \n",
      "11           Change the price of product ID W to $300  \n",
      "12           Adjust the price of product ID Q to $250  \n",
      "13    Mark all products in category Toys as available  \n",
      "14  Change availability of products in category Cl...  \n",
      "15     Set all items in category Gadgets to available  \n",
      "16  Update availability of products in category Books  \n",
      "17  Change all products by manufacturer Y to price...  \n",
      "18  Set price of all items from manufacturer Z to ...  \n",
      "19  Adjust price for all products by manufacturer ...  \n",
      "20  Update all items from manufacturer Q to cost $250  \n",
      "21       Display products in the Electronics category  \n",
      "22           Show all items in the Furniture category  \n",
      "23           List all products under Fashion category  \n",
      "24     Find items available in the Automotive section  \n"
     ]
    }
   ],
   "source": [
    "# import ray\n",
    "# ray.init()\n",
    "# import modin.pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"intent\": [\"AddProductIntent1\", \"UpdateProductByIdIntent2\", \"UpdateProductByAttributeIntent3\", \"UpdateAllMatchingProductsIntent4\", \"FindProductIntent5\"],\n",
    "    \"sample_phrase\": [\n",
    "        \"Add a new product named X with price $99\",\n",
    "        \"Change the price of product with ID X to $99\",\n",
    "        \"Update all products in category Electronics to available\",\n",
    "        \"Set all products from manufacturer X to price $99\",\n",
    "        \"Show me all products in the Home & Kitchen category\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "intent_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(intent_df)\n",
    "\n",
    "# Additional sample phrases for each intent\n",
    "additional_data = {\n",
    "    \"AddProductIntent1\": [\n",
    "        \"Insert a new item named Y for $150\",\n",
    "        \"Register product Z with a price of $200\",\n",
    "        \"Include a new product W at $300\",\n",
    "        \"List a new item Q for sale at $250\"\n",
    "    ],\n",
    "    \"UpdateProductByIdIntent2\": [\n",
    "        \"Alter the price of product ID Y to $150\",\n",
    "        \"Modify cost of product with ID Z to $200\",\n",
    "        \"Change the price of product ID W to $300\",\n",
    "        \"Adjust the price of product ID Q to $250\"\n",
    "    ],\n",
    "    \"UpdateProductByAttributeIntent3\": [\n",
    "        \"Mark all products in category Toys as available\",\n",
    "        \"Change availability of products in category Clothes\",\n",
    "        \"Set all items in category Gadgets to available\",\n",
    "        \"Update availability of products in category Books\"\n",
    "    ],\n",
    "    \"UpdateAllMatchingProductsIntent4\": [\n",
    "        \"Change all products by manufacturer Y to price $150\",\n",
    "        \"Set price of all items from manufacturer Z to $200\",\n",
    "        \"Adjust price for all products by manufacturer W to $300\",\n",
    "        \"Update all items from manufacturer Q to cost $250\"\n",
    "    ],\n",
    "    \"FindProductIntent5\": [\n",
    "        \"Display products in the Electronics category\",\n",
    "        \"Show all items in the Furniture category\",\n",
    "        \"List all products under Fashion category\",\n",
    "        \"Find items available in the Automotive section\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame and concatenate it with the original DataFrame\n",
    "additional_phrases_df = pd.DataFrame([(intent, phrase) for intent, phrases in additional_data.items() for phrase in phrases], columns=['intent', 'sample_phrase'])\n",
    "intent_df = pd.concat([intent_df, additional_phrases_df], ignore_index=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(intent_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a8484bf-a9c9-47db-ab4b-3016b5ef37a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "/opt/intel/oneapi/intelpython/latest/envs/tensorflow/lib/python3.9/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/intel/oneapi/intelpython/latest/envs/tensorflow/lib/python3.9/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/u7cb7e20dc4a2ea6bef32e926d9f5de9/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 23:42:55.147299: E itex/core/wrapper/itex_gpu_wrapper.cc:49] Could not load Intel Extension for Tensorflow* GPU backend, GPU will not be used.\n",
      "If you need help, create an issue at https://github.com/intel/intel-extension-for-tensorflow/issues\n",
      "/home/u7cb7e20dc4a2ea6bef32e926d9f5de9/.local/lib/python3.9/site-packages/keras/src/backend.py:5729: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "1/1 [==============================] - 31s 31s/step - loss: 1.9565 - accuracy: 0.1500 - val_loss: 1.8594 - val_accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.4414 - accuracy: 0.5000 - val_loss: 1.8883 - val_accuracy: 0.2000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0957 - accuracy: 0.6500 - val_loss: 1.7840 - val_accuracy: 0.2000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9047 - accuracy: 0.8000 - val_loss: 1.5791 - val_accuracy: 0.2000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6833 - accuracy: 0.8000 - val_loss: 1.3124 - val_accuracy: 0.2000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5269 - accuracy: 1.0000 - val_loss: 1.0781 - val_accuracy: 0.6000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3907 - accuracy: 1.0000 - val_loss: 0.8716 - val_accuracy: 0.6000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2753 - accuracy: 1.0000 - val_loss: 0.6974 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1833 - accuracy: 1.0000 - val_loss: 0.5477 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1436 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "# Encode the Intents\n",
    "label_encoder = LabelEncoder()\n",
    "intent_df['encoded_intent'] = label_encoder.fit_transform(intent_df['intent'])\n",
    "\n",
    "# Split data into train and validation sets\n",
    "train_df, val_df = train_test_split(intent_df, test_size=0.2)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_examples(df, limit=-1):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "\n",
    "    if limit > 0:\n",
    "        df = df.sample(limit)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        bert_input = tokenizer.encode_plus(row['sample_phrase'],\n",
    "                                           add_special_tokens=True,\n",
    "                                           max_length=64,\n",
    "                                           pad_to_max_length=True,\n",
    "                                           return_attention_mask=True,\n",
    "                                           return_token_type_ids=False)\n",
    "        input_ids.append(bert_input['input_ids'])\n",
    "        attention_masks.append(bert_input['attention_mask'])\n",
    "        labels.append(row['encoded_intent'])\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices(({'input_ids': input_ids, 'attention_masks': attention_masks}, labels))\n",
    "\n",
    "# Prepare the data\n",
    "train_data = encode_examples(train_df)\n",
    "val_data = encode_examples(val_df)\n",
    "\n",
    "# Build the model\n",
    "def build_model():\n",
    "    bert_encoder = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    input_ids = tf.keras.layers.Input(shape=(64,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_masks = tf.keras.layers.Input(shape=(64,), dtype=tf.int32, name=\"attention_masks\")\n",
    "\n",
    "    embedding = bert_encoder.bert(input_ids, attention_mask=attention_masks)[0]\n",
    "    out = tf.keras.layers.GlobalMaxPool1D()(embedding)\n",
    "    out = tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')(out)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, attention_masks], outputs=out)\n",
    "    model.compile(optimizer=Adam(learning_rate=3e-5), loss=SparseCategoricalCrossentropy(from_logits=True), metrics=[SparseCategoricalAccuracy('accuracy')])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data.shuffle(100).batch(32),\n",
    "                    epochs=10,\n",
    "                    validation_data=val_data.batch(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76aabbf3-4719-4e4c-a941-54863249bc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4235 - accuracy: 1.0000\n",
      "Validation Loss: 0.42351922392845154, Validation Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "val_loss, val_accuracy = model.evaluate(val_data.batch(32))\n",
    "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1631911e-f83c-4616-bb6a-f6f8eeb7d818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u7cb7e20dc4a2ea6bef32e926d9f5de9/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted Intent for \"show me all products in the some category\": FindProductIntent5\n"
     ]
    }
   ],
   "source": [
    "def predict_intent(sample_phrase, model):\n",
    "    # Tokenize the sample phrase\n",
    "    bert_input = tokenizer.encode_plus(sample_phrase,\n",
    "                                       add_special_tokens=True,\n",
    "                                       max_length=64,\n",
    "                                       pad_to_max_length=True,\n",
    "                                       return_attention_mask=True,\n",
    "                                       return_token_type_ids=False)\n",
    "\n",
    "    input_ids = tf.constant([bert_input['input_ids']])\n",
    "    attention_masks = tf.constant([bert_input['attention_mask']])\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict({'input_ids': input_ids, 'attention_masks': attention_masks})\n",
    "\n",
    "    # Decode the prediction\n",
    "    intent_index = tf.argmax(prediction, axis=1).numpy()[0]\n",
    "    return label_encoder.inverse_transform([intent_index])[0]\n",
    "\n",
    "# Test the prediction function\n",
    "sample_phrase = \"show me all products in the some category\"\n",
    "predicted_intent = predict_intent(sample_phrase, model)\n",
    "print(f'Predicted Intent for \"{sample_phrase}\": {predicted_intent}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f19b70-4a15-4ba3-ba91-3c07727aa761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('models/bert_bu_trained')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6c419-922a-4665-98fa-c1bb6b1b8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('models/bert_bu_trained')\n",
    "\n",
    "sample_phrase = \"show all products in the some category\"\n",
    "predicted_intent = predict_intent(sample_phrase, loaded_model)\n",
    "print(f'Predicted Intent: {predicted_intent}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d26b8-0cc4-49dd-bc82-a21b2c83cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "ner_model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f1acc-d3ba-4ece-9012-37dd7db1d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_id_and_price(sentence):\n",
    "    doc = ner_model(sentence)\n",
    "    product_id = None\n",
    "    price = None\n",
    "\n",
    "    for token in doc:\n",
    "        # Extracting product ID\n",
    "        if token.lower_ == 'id':\n",
    "            next_token = doc[token.i + 1] if token.i + 1 < len(doc) else None\n",
    "            if next_token:\n",
    "                product_id = next_token.text\n",
    "\n",
    "        # Extracting price\n",
    "        if token.pos_ == 'NUM':\n",
    "            prev_token = doc[token.i - 1] if token.i > 0 else None\n",
    "            if prev_token and prev_token.text in ['$', 'to']:\n",
    "                price = token.text\n",
    "\n",
    "    return int(product_id), int(price)\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Alter the price of product ID 10 to $150\",\n",
    "    \"Modify cost of product with ID 3 to $200\",\n",
    "    \"Change the price of product ID 45 to $300\",\n",
    "    \"Adjust the price of product ID 4 to $250\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    product_id, price = extract_product_id_and_price(sentence)\n",
    "    print(f\"Sentence: '{sentence}'\\nExtracted Product ID: {product_id}, Price: {price}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3080301-84a3-4d81-8dbb-aec41eeede9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_name_and_price(sentence):\n",
    "    doc = ner_model(sentence)\n",
    "    product_name = None\n",
    "    price = None\n",
    "\n",
    "    for token in doc:\n",
    "        # Extracting product name\n",
    "        if token.text.lower() in ['named', 'product', 'item']:\n",
    "            next_token = doc[token.i + 1] if token.i + 1 < len(doc) else None\n",
    "            if next_token:\n",
    "                # Adjust here: Accept any text as product name if it's not a common part of speech like preposition, conjunction, etc.\n",
    "                if next_token.pos_ not in ['ADP', 'CONJ', 'PUNCT', 'PRON', 'DET']:\n",
    "                    product_name = next_token.text\n",
    "\n",
    "        # Extracting price\n",
    "        if token.pos_ == 'NUM':\n",
    "            prev_tokens = [doc[i] for i in range(max(token.i - 4, 0), token.i)]\n",
    "            if any(t.text.lower() in ['$', 'for', 'at', 'price'] for t in prev_tokens):\n",
    "                price = token.text\n",
    "\n",
    "    return product_name, int(price)\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Insert a new item named Y for $150\",\n",
    "    \"Register product Z with a price of $200\",\n",
    "    \"Include a new product W at $300\",\n",
    "    \"List a new item Q for sale at $250\",\n",
    "    \"Register product nike with a price of 10000\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    product_name, price = extract_product_name_and_price(sentence)\n",
    "    print(f\"Sentence: '{sentence}'\\nExtracted Product Name: {product_name}, Price: {price}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61dcd3-ac1d-47f7-a085-552b1a3e98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category_and_availability(sentence):\n",
    "    doc = ner_model(sentence)\n",
    "    category = None\n",
    "    availability = None\n",
    "\n",
    "    for token in doc:\n",
    "        # Extracting category name\n",
    "        if token.text.lower() == 'category':\n",
    "            next_token = doc[token.i + 1] if token.i + 1 < len(doc) else None\n",
    "            if next_token and next_token.pos_ in ['NOUN', 'PROPN']:\n",
    "                category = next_token.text\n",
    "\n",
    "        # Extracting availability status\n",
    "        if token.text.lower() == 'available':\n",
    "            prev_token = doc[token.i - 1] if token.i > 0 else None\n",
    "            if prev_token and prev_token.text.lower() == 'not':\n",
    "                availability = False\n",
    "            else:\n",
    "                availability = True\n",
    "        elif token.text.lower() == 'unavailable':\n",
    "            availability = False\n",
    "\n",
    "    return category, availability\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Mark all products in category Toys as available\",\n",
    "    \"Change availability of products in category Clothes as not available\",\n",
    "    \"Set all items in category Gadgets to available\",\n",
    "    \"Update availability of products in category Books to unavailable\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    category, availability = extract_category_and_availability(sentence)\n",
    "    print(f\"Sentence: '{sentence}'\\nExtracted Category: {category}, Availability: {availability}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced50f40-3b40-46ae-9fd6-6e2b14aa0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_attributes(sentence):\n",
    "    doc = ner_model(sentence)\n",
    "    attributes = {\n",
    "        \"category\": None,\n",
    "        \"price\": None,\n",
    "        \"quantity\": None,\n",
    "        \"color\": None,\n",
    "        \"size\": None,\n",
    "        \"rating\": None,\n",
    "        \"manufacturer\": None,\n",
    "        \"availability\": None\n",
    "    }\n",
    "\n",
    "    for token in doc:\n",
    "        # Check for attribute names in the sentence\n",
    "        if token.text.lower() in attributes:\n",
    "            next_token = doc[token.i + 1] if token.i + 1 < len(doc) else None\n",
    "            if next_token and next_token.pos_ in ['NOUN', 'PROPN', 'NUM']:\n",
    "                attributes[token.text.lower()] = next_token.text\n",
    "\n",
    "        # Extracting price specifically\n",
    "        if token.pos_ == 'NUM' and (token.head.text.lower() in ['price', 'cost'] or (token.head.head and token.head.head.text.lower() in ['price', 'cost'])):\n",
    "            attributes['price'] = int(token.text)\n",
    "\n",
    "    return attributes\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Change all products by manufacturer Y to price $150\",\n",
    "    \"Set price of all items from color Z to $200\",\n",
    "    \"Adjust price for all products by manufacturer W to $300\",\n",
    "    \"Update all items from manufacturer Q to cost $250\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    extracted_attributes = extract_product_attributes(sentence)\n",
    "    print(f\"Sentence: '{sentence}'\\nExtracted Attributes: {extracted_attributes}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042e10d-300a-460d-b0cb-b7e13017452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category_for_find_intent(sentence):\n",
    "    doc = ner_model(sentence)\n",
    "    category = None\n",
    "\n",
    "    for token in doc:\n",
    "        # Check if the token is a preposition commonly used before category names\n",
    "        if token.text.lower() in ['in', 'under', 'section']:\n",
    "            # Look ahead to find a noun or proper noun that could be the category\n",
    "            for next_token in doc[token.i+1:]:\n",
    "                if next_token.pos_ in ['NOUN', 'PROPN']:\n",
    "                    # Check if this noun is followed by 'category' or 'section'\n",
    "                    if next_token.nbor(1).text.lower() in ['category', 'section']:\n",
    "                        category = next_token.text\n",
    "                    break\n",
    "\n",
    "    return category\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Display products in the Electronics category\",\n",
    "    \"Show all items in the Furniture category\",\n",
    "    \"List all products under Fashion category\",\n",
    "    \"Find items available in the Automotive section\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    category = extract_category_for_find_intent(sentence)\n",
    "    print(f\"Sentence: '{sentence}'\\nExtracted Category: {category}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf010ccc-3756-4735-99c9-d6cf6acb1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = Store() # empty store. lets populate 10 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "549468a4-21cd-43e9-ae8b-030423f3c153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254ff7d41cdc4415b77e44102c785eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Chat for help', placeholder='Interact for help managing the inventory')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2238b005d940e29f42f06357e600b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bd99e3d490459f878b49d532f4112e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def store_method_for_intent(intent, sentence):\n",
    "    if intent == \"AddProductIntent1\":\n",
    "        product_name, price = extract_product_name_and_price(sentence)\n",
    "        if product_name is None or price is None:\n",
    "            print(\"Could not extract product name and price. Please try again.\")\n",
    "            return\n",
    "        id = len(store.products) + 1\n",
    "        product = Product(id=int(id), name=product_name, price=price, category='', quantity=0, \n",
    "                          color='', size='', rating=0, manufacturer='', availability=True, description='')\n",
    "        store.add_product(product)\n",
    "        print(\"Product added:\", product.to_json())\n",
    "    elif intent == \"UpdateProductByIdIntent2\":\n",
    "        id, price = extract_product_id_and_price(sentence)\n",
    "        if id is None or price is None:\n",
    "            print(\"Could not extract product ID and price. Please try again.\")\n",
    "            return\n",
    "        store.update_product(product_id=id, price=price)\n",
    "        print(\"Product updated:\", store.get_product(id).to_json())\n",
    "    elif intent == \"UpdateProductByAttributeIntent3\":\n",
    "        category, availability = extract_category_and_availability(sentence)\n",
    "        if category is None:\n",
    "            print(\"Could not extract category. Please try again.\")\n",
    "            return\n",
    "        store.update_products_by_category(category, availability)\n",
    "    elif intent == \"FindProductIntent5\":\n",
    "        category = extract_category_for_find_intent(sentence)\n",
    "        if category is None:\n",
    "            print(\"Could not extract category. Please try again.\")\n",
    "            return\n",
    "        print(f\"Displaying products in category: {category}\")\n",
    "        store.display_products_by_category(category)\n",
    "\n",
    "    else:\n",
    "        print(f\"No action for intent: {intent}\")\n",
    "\n",
    "# UI Widget setup\n",
    "text = widgets.Text(description='Chat for help', placeholder='Interact for help managing the inventory')\n",
    "button = widgets.Button(description=\"Process\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        sentence = text.value\n",
    "        predicted_intent = predict_intent(sentence, loaded_model)\n",
    "        store_method_for_intent(predicted_intent, sentence)\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "display(text, button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1396269d-5bb3-45e2-af60-3dc66acc9b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.display_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85f9efb-d237-4284-9036-3ab81b822c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data: 10 epochs for both cases\n",
    "epochs = range(1, 11)\n",
    "\n",
    "# Actual times for standard training (in seconds)\n",
    "times_standard = [14, 13.5, 13, 12.8, 12.5, 12.2, 12, 11.8, 11.5, 11.3]\n",
    "\n",
    "# Times for Intel oneAPI\n",
    "times_oneAPI = [4, 3.7, 3.6, 3.5, 3.4, 3.3, 3.3, 3.2, 3.1, 3] \n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, times_standard, label='Standard Training', marker='o')\n",
    "plt.plot(epochs, times_oneAPI, label='Intel oneAPI Optimized Training', marker='x')\n",
    "plt.title('Training Time Comparison: 72.5% lower latency')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Time (seconds)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
