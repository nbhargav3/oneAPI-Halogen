{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3941040da39a488b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:34:49.115520Z",
     "start_time": "2023-12-16T00:34:34.186336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/automata/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\r\n",
      "Requirement already satisfied: jinja2 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.7.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/automata/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/automata/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/automata/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/automata/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/automata/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/automata/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/automata/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\r\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\r\n",
      "Installing collected packages: en-core-web-sm\r\n",
      "Successfully installed en-core-web-sm-3.7.1\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-learn-intelex Faker spacy ipywidgets\n",
    "# !python -m spacy download en_core_web_sm\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23423d522e0709dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:20:34.012434Z",
     "start_time": "2023-12-16T00:19:03.700055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\r\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/92/2d/880fcd65e4414b05088193e6f2cfb86fdf90003dd2dd0f4d1bc465348f0e/tensorflow-2.15.0-cp311-cp311-macosx_10_15_x86_64.whl.metadata\r\n",
      "  Downloading tensorflow-2.15.0-cp311-cp311-macosx_10_15_x86_64.whl.metadata (4.2 kB)\r\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\r\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\r\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\r\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\r\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\r\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\r\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\r\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\r\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\r\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.9.0)\r\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/c9/ea/fe2a69cc6cfebf7c7ee8a6357566fc1cbb91632bde5869b669a396accb5f/libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl.metadata\r\n",
      "  Using cached libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\r\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for ml-dtypes~=0.2.0 from https://files.pythonhosted.org/packages/15/da/43bee505963da0c730ee50e951c604bfdb90d4cccc9c0044c946b10e68a7/ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl.metadata\r\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/automata/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.24.3)\r\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\r\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\r\n",
      "Requirement already satisfied: packaging in /Users/automata/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\r\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\r\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/e6/db/7b2edc72807d45d72f9db42f3eb86ddaf37f9e55d923159b1dbfc9d835bc/protobuf-4.25.1-cp37-abi3-macosx_10_9_universal2.whl.metadata\r\n",
      "  Using cached protobuf-4.25.1-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\r\n",
      "Requirement already satisfied: setuptools in /Users/automata/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\r\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl.metadata\r\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/automata/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.7.1)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\r\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\r\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/3d/34/252794e3f737594f8ac4ac9f2ee9ba7b806b6825832af3ff9b2fd893ce8f/tensorflow_io_gcs_filesystem-0.34.0-cp311-cp311-macosx_10_14_x86_64.whl.metadata\r\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp311-cp311-macosx_10_14_x86_64.whl.metadata (14 kB)\r\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\r\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/5c/45/8708497bc482cc7bf3779df9cf00c8e9efe1df5cd29b77e3eb060c141f84/grpcio-1.60.0-cp311-cp311-macosx_10_10_universal2.whl.metadata\r\n",
      "  Downloading grpcio-1.60.0-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\r\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\r\n",
      "  Obtaining dependency information for tensorboard<2.16,>=2.15 from https://files.pythonhosted.org/packages/6e/0c/1059a6682cf2cc1fcc0d5327837b5672fe4f5574255fa5430d0a8ceb75e9/tensorboard-2.15.1-py3-none-any.whl.metadata\r\n",
      "  Using cached tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for tensorflow-estimator<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/b6/c8/2f823c8958d5342eafc6dd3e922f0cc4fcf8c2e0460284cc462dae3b60a0/tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata\r\n",
      "  Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for keras<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/fc/a7/0d4490de967a67f68a538cc9cdb259bff971c4b5787f7765dc7c8f118f71/keras-2.15.0-py3-none-any.whl.metadata\r\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\r\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow)\r\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/f4/d2/9f6f3b9c0fd486617816cff42e856afea079d0bad99f0e60dc186c76b881/google_auth-2.25.2-py2.py3-none-any.whl.metadata\r\n",
      "  Downloading google_auth-2.25.2-py2.py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow)\r\n",
      "  Obtaining dependency information for google-auth-oauthlib<2,>=0.5 from https://files.pythonhosted.org/packages/71/bf/9e125754d1adb3bc4bd206c4e5df756513b1d23675ac06caa471278d1f3f/google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata\r\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/automata/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.4.1)\r\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\r\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/cb/d3/a164038605494d49acc4f9cda1c0bc200b96382c53edd561387263bb181d/protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl.metadata\r\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (540 bytes)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/automata/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\r\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow)\r\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/b7/85/dabeaf902892922777492e1d253bb7e1264cadce3cea932f7ff599e53fea/tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata\r\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/automata/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.2.3)\r\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\r\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a2/91/2d843adb9fbd911e0da45fbf6f18ca89d07a087c3daa23e955584f90ebf4/cachetools-5.3.2-py3-none-any.whl.metadata\r\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/automata/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.2.8)\r\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\r\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\r\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow)\r\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/automata/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/automata/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/automata/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/automata/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/automata/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/automata/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.8)\r\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow)\r\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\r\n",
      "Downloading tensorflow-2.15.0-cp311-cp311-macosx_10_15_x86_64.whl (239.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.1/239.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\r\n",
      "\u001b[?25hDownloading absl_py-2.0.0-py3-none-any.whl (130 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hUsing cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\r\n",
      "Downloading grpcio-1.60.0-cp311-cp311-macosx_10_10_universal2.whl (9.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hUsing cached keras-2.15.0-py3-none-any.whl (1.7 MB)\r\n",
      "Using cached libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl (24.5 MB)\r\n",
      "Downloading ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hUsing cached tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\r\n",
      "Downloading protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.3/400.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hUsing cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\r\n",
      "Downloading tensorflow_io_gcs_filesystem-0.34.0-cp311-cp311-macosx_10_14_x86_64.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hUsing cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\r\n",
      "Downloading google_auth-2.25.2-py2.py3-none-any.whl (184 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.2/184.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\r\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\r\n",
      "Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\r\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\r\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.25.2 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.0 keras-2.15.0 libclang-16.0.6 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.4.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23c7d3b17c0186a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:18:28.713363Z",
     "start_time": "2023-12-16T00:18:28.706942Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class Product:\n",
    "    def __init__(self, id, name, category = 'Electronics', price = 100, quantity = 10, color = None, size = None, rating = None, manufacturer = None, availability = None, description = None):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.category = category\n",
    "        self.price = price\n",
    "        self.quantity = quantity\n",
    "        self.color = color\n",
    "        self.size = size\n",
    "        self.rating = rating\n",
    "        self.manufacturer = manufacturer\n",
    "        self.availability = availability\n",
    "        self.description = description\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps(self)\n",
    "\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n",
    "\n",
    "\n",
    "class Store:\n",
    "    def __init__(self):\n",
    "        self.products = {}\n",
    "\n",
    "    def add_product(self, product):\n",
    "        self.products[product.id] = product\n",
    "\n",
    "    def update_product(self, product_id, **kwargs):\n",
    "        if product_id in self.products:\n",
    "            for key, value in kwargs.items():\n",
    "                setattr(self.products[product_id], key, value)\n",
    "        else:\n",
    "            print(f\"Product with id {product_id} not found.\")\n",
    "\n",
    "    def update_availability(self, product_id, new_availability):\n",
    "        if product_id in self.products:\n",
    "            self.products[product_id].availability = new_availability\n",
    "            print(f\"Product ID {product_id} availability updated to {new_availability}.\")\n",
    "        else:\n",
    "            print(f\"Product with ID {product_id} not found.\")\n",
    "\n",
    "    def get_product(self, id):\n",
    "        return self.products.get(id, None)\n",
    "\n",
    "    def display_products(self):\n",
    "        for product in self.products.values():\n",
    "            print(product.to_json())\n",
    "\n",
    "    def display_products_by_category(self, category):\n",
    "        found = False\n",
    "        for product in self.products.values():\n",
    "            if product.category.lower() == category.lower():\n",
    "                print(product.to_json())\n",
    "                found = True\n",
    "        if not found:\n",
    "            print(f\"No products found in category: {category}\")\n",
    "\n",
    "    def update_products_by_category(self, category, new_availability):\n",
    "        found = False\n",
    "        for product in self.products.values():\n",
    "            if product.category.lower() == category.lower():\n",
    "                product.availability = new_availability\n",
    "                print(f\"Updated {product.name} to {'available' if new_availability else 'unavailable'}\")\n",
    "                found = True\n",
    "        if not found:\n",
    "            print(f\"No products found in category: {category}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93834d378f41d32d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:37:50.038074Z",
     "start_time": "2023-12-16T00:37:49.946586Z"
    }
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Function to generate and add products to the store\n",
    "def generate_products(store, n, categories):\n",
    "    fake = Faker()\n",
    "    for _ in range(n):\n",
    "        id = fake.unique.uuid4()\n",
    "        name = f\"{fake.word().capitalize()} {fake.random_element(elements=('Pro', 'Max', 'Plus'))}\"\n",
    "        category = random.choice(categories)\n",
    "        price = round(random.uniform(10, 1000), 2)\n",
    "        quantity = random.randint(1, 100)\n",
    "        color = fake.color_name()\n",
    "        size = random.choice(['Small', 'Medium', 'Large'])\n",
    "        rating = round(random.uniform(1, 5), 1)\n",
    "        manufacturer = fake.company()\n",
    "        availability = random.choice([True, False])\n",
    "        description = fake.text()\n",
    "\n",
    "        product = Product(id, name, category, price, quantity, color, size, rating, manufacturer, availability, description)\n",
    "        store.add_product(product)\n",
    "\n",
    "# Create a store instance\n",
    "store = Store()\n",
    "\n",
    "# Define the number of products and categories\n",
    "num_products = 10\n",
    "categories = ['Electronics', 'Clothing', 'Home & Kitchen']\n",
    "\n",
    "# Generate products and add them to the store\n",
    "generate_products(store, num_products, categories)\n",
    "\n",
    "# Display products in the store\n",
    "# store.display_products()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2827a0385e3b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:18:32.241331Z",
     "start_time": "2023-12-16T00:18:32.229750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"availability\": true,\n",
      "    \"category\": \"Electronics\",\n",
      "    \"color\": \"Silver\",\n",
      "    \"description\": \"Or future whole while bit. Responsibility individual between as bring.\\nMiddle defense up bar over push perhaps. Charge discover group before. Contain budget poor surface letter foot process.\",\n",
      "    \"id\": \"7931cd70-6795-4239-abfb-38c3df647cc2\",\n",
      "    \"manufacturer\": \"Alexander-Duncan\",\n",
      "    \"name\": \"Almost Max\",\n",
      "    \"price\": 213.07,\n",
      "    \"quantity\": 57,\n",
      "    \"rating\": 2.8,\n",
      "    \"size\": \"Medium\"\n",
      "}\n",
      "Product with ID 7931cd70-6795-4239-abfb-38c3df647cc2 updated.\n",
      "{\n",
      "    \"availability\": true,\n",
      "    \"category\": \"Electronics\",\n",
      "    \"color\": \"Silver\",\n",
      "    \"description\": \"Or future whole while bit. Responsibility individual between as bring.\\nMiddle defense up bar over push perhaps. Charge discover group before. Contain budget poor surface letter foot process.\",\n",
      "    \"id\": \"7931cd70-6795-4239-abfb-38c3df647cc2\",\n",
      "    \"manufacturer\": \"Alexander-Duncan\",\n",
      "    \"name\": \"Almost Max\",\n",
      "    \"price\": 0,\n",
      "    \"quantity\": 57,\n",
      "    \"rating\": 2.8,\n",
      "    \"size\": \"Medium\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Function to find and update a product in the store\n",
    "def find_and_update_product(store, product_id, **update_attrs):\n",
    "    # Check if the product exists in the store\n",
    "    if product_id in store.products:\n",
    "        # Update the product attributes\n",
    "        store.update_product(product_id, **update_attrs)\n",
    "        print(f\"Product with ID {product_id} updated.\")\n",
    "        # Display the updated product details\n",
    "        print(store.get_product(product_id).to_json())\n",
    "    else:\n",
    "        print(f\"Product with ID {product_id} not found.\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a product ID (you can get one from the existing products in the store)\n",
    "sample_product_id = list(store.products.keys())[0]  # Get the ID of the first product in the store\n",
    "print(store.get_product(sample_product_id).to_json())\n",
    "# Update the product (for example, change its price and availability)\n",
    "find_and_update_product(store, sample_product_id, price=0, availability=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50704a5f02caecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:18:33.861529Z",
     "start_time": "2023-12-16T00:18:33.846394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID 7931cd70-6795-4239-abfb-38c3df647cc2 availability updated to False.\n",
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Electronics\",\n",
      "    \"color\": \"Silver\",\n",
      "    \"description\": \"Or future whole while bit. Responsibility individual between as bring.\\nMiddle defense up bar over push perhaps. Charge discover group before. Contain budget poor surface letter foot process.\",\n",
      "    \"id\": \"7931cd70-6795-4239-abfb-38c3df647cc2\",\n",
      "    \"manufacturer\": \"Alexander-Duncan\",\n",
      "    \"name\": \"Almost Max\",\n",
      "    \"price\": 0,\n",
      "    \"quantity\": 57,\n",
      "    \"rating\": 2.8,\n",
      "    \"size\": \"Medium\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example usage to update availability:\n",
    "sample_product_id = list(store.products.keys())[0]  # Get the ID of the first product\n",
    "store.update_availability(sample_product_id, False)  # Update availability to False\n",
    "\n",
    "# Display the updated product details\n",
    "print(store.get_product(sample_product_id).to_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65272809912fa68d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:18:34.887804Z",
     "start_time": "2023-12-16T00:18:34.874302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Electronics\",\n",
      "    \"color\": \"Silver\",\n",
      "    \"description\": \"New description\",\n",
      "    \"id\": \"7931cd70-6795-4239-abfb-38c3df647cc2\",\n",
      "    \"manufacturer\": \"Alexander-Duncan\",\n",
      "    \"name\": \"New Product Name\",\n",
      "    \"price\": 299.99,\n",
      "    \"quantity\": 57,\n",
      "    \"rating\": 2.8,\n",
      "    \"size\": \"Medium\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example usage to update multiple product attributes:\n",
    "sample_product_id = list(store.products.keys())[0]  # Assume this is the product ID\n",
    "store.update_product(sample_product_id, name=\"New Product Name\", description=\"New description\", price=299.99)\n",
    "\n",
    "# Display the updated product\n",
    "print(store.get_product(sample_product_id).to_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf575def6a4c7d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:18:35.743846Z",
     "start_time": "2023-12-16T00:18:35.738798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Electronics\",\n",
      "    \"color\": \"Silver\",\n",
      "    \"description\": \"New description\",\n",
      "    \"id\": \"7931cd70-6795-4239-abfb-38c3df647cc2\",\n",
      "    \"manufacturer\": \"Alexander-Duncan\",\n",
      "    \"name\": \"New Product Name\",\n",
      "    \"price\": 299.99,\n",
      "    \"quantity\": 57,\n",
      "    \"rating\": 2.8,\n",
      "    \"size\": \"Medium\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(store.get_product(sample_product_id).to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "989ccb7f333fffca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:18:36.718604Z",
     "start_time": "2023-12-16T00:18:36.675449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added new product:\n",
      "{\n",
      "    \"availability\": true,\n",
      "    \"category\": \"Clothing\",\n",
      "    \"color\": \"Magenta\",\n",
      "    \"description\": \"Serve prevent bag artist church skill contain. Art image send order. Century part dream me matter. Middle picture wonder.\",\n",
      "    \"id\": \"d87306e7-a818-4773-abc4-ec2a1c6659e6\",\n",
      "    \"manufacturer\": \"Ferguson-Holmes\",\n",
      "    \"name\": \"Have Max\",\n",
      "    \"price\": 341.95,\n",
      "    \"quantity\": 97,\n",
      "    \"rating\": 4.2,\n",
      "    \"size\": \"Small\"\n",
      "}\n",
      "\n",
      "All products in the store:\n",
      "{\n",
      "    \"availability\": true,\n",
      "    \"category\": \"Clothing\",\n",
      "    \"color\": \"Magenta\",\n",
      "    \"description\": \"Serve prevent bag artist church skill contain. Art image send order. Century part dream me matter. Middle picture wonder.\",\n",
      "    \"id\": \"d87306e7-a818-4773-abc4-ec2a1c6659e6\",\n",
      "    \"manufacturer\": \"Ferguson-Holmes\",\n",
      "    \"name\": \"Have Max\",\n",
      "    \"price\": 341.95,\n",
      "    \"quantity\": 97,\n",
      "    \"rating\": 4.2,\n",
      "    \"size\": \"Small\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Assuming the Product and Store classes are defined as earlier\n",
    "\n",
    "def create_product():\n",
    "    fake = Faker()\n",
    "    id = fake.unique.uuid4()\n",
    "    name = f\"{fake.word().capitalize()} {fake.random_element(elements=('Pro', 'Max', 'Plus'))}\"\n",
    "    category = random.choice(['Electronics', 'Clothing', 'Home & Kitchen'])\n",
    "    price = round(random.uniform(10, 1000), 2)\n",
    "    quantity = random.randint(1, 100)\n",
    "    color = fake.color_name()\n",
    "    size = random.choice(['Small', 'Medium', 'Large'])\n",
    "    rating = round(random.uniform(1, 5), 1)\n",
    "    manufacturer = fake.company()\n",
    "    availability = random.choice([True, False])\n",
    "    description = fake.text()\n",
    "\n",
    "    return Product(id, name, category, price, quantity, color, size, rating, manufacturer, availability, description)\n",
    "\n",
    "# Create a store instance if not already created\n",
    "demo_store = Store()\n",
    "\n",
    "# Create a new product\n",
    "new_product = create_product()\n",
    "\n",
    "# Add the new product to the store\n",
    "demo_store.add_product(new_product)\n",
    "\n",
    "# Display the added product\n",
    "print(\"Added new product:\")\n",
    "print(new_product.to_json())\n",
    "\n",
    "# Optionally, display all products in the store\n",
    "print(\"\\nAll products in the store:\")\n",
    "demo_store.display_products()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d66b58cbaa5e80a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:18:37.532245Z",
     "start_time": "2023-12-16T00:18:37.525635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Original store products\n",
    "# store.display_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa7b4452e811bab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:18:38.896576Z",
     "start_time": "2023-12-16T00:18:38.890908Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_product_by_attribute(store, **attributes):\n",
    "    for product in store.products.values():\n",
    "        if all(getattr(product, key, None) == value for key, value in attributes.items()):\n",
    "            return product\n",
    "    return None\n",
    "\n",
    "def update_product_by_attribute(store, search_attrs, **update_attrs):\n",
    "    product = find_product_by_attribute(store, **search_attrs)\n",
    "    if product:\n",
    "        product_id = product.id\n",
    "        store.update_product(product_id, **update_attrs)\n",
    "        print(f\"Product with attributes {search_attrs} updated.\")\n",
    "        print(product.to_json())\n",
    "    else:\n",
    "        print(f\"No product found with attributes {search_attrs}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc640b1731c3dcf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:18:39.917612Z",
     "start_time": "2023-12-16T00:18:39.901604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Electronics\",\n",
      "    \"color\": \"Silver\",\n",
      "    \"description\": \"New description\",\n",
      "    \"id\": \"7931cd70-6795-4239-abfb-38c3df647cc2\",\n",
      "    \"manufacturer\": \"Alexander-Duncan\",\n",
      "    \"name\": \"New Product Name\",\n",
      "    \"price\": 299.99,\n",
      "    \"quantity\": 57,\n",
      "    \"rating\": 2.8,\n",
      "    \"size\": \"Medium\"\n",
      "}\n",
      "No product found with attributes {'color': 'DarkSalmon'}.\n"
     ]
    }
   ],
   "source": [
    "# Example: Find a product by name and update its price\n",
    "sample_product_id = list(store.products.keys())[0]\n",
    "sample_product = store.get_product(sample_product_id)\n",
    "print(sample_product.to_json())\n",
    "search_attributes = {'color': 'DarkSalmon'}\n",
    "update_attributes = {'price': 200.00}\n",
    "update_product_by_attribute(store, search_attributes, **update_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b2e84d89d995ab7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:18:40.966875Z",
     "start_time": "2023-12-16T00:18:40.952890Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_all_matching_products(store, search_attrs, **update_attrs):\n",
    "    updated_products = []\n",
    "    for product_id, product in store.products.items():\n",
    "        if all(getattr(product, key, None) == value for key, value in search_attrs.items()):\n",
    "            store.update_product(product_id, **update_attrs)\n",
    "            updated_products.append(product_id)\n",
    "\n",
    "    if updated_products:\n",
    "        print(f\"Updated products with IDs: {updated_products}\")\n",
    "        for pid in updated_products:\n",
    "            print(store.get_product(pid).to_json())\n",
    "    else:\n",
    "        print(f\"No products found with attributes {search_attrs}.\")\n",
    "\n",
    "# Example: Update all products with a specific category to a new price\n",
    "# search_attributes = {'category': 'Electronics'}\n",
    "# update_attributes = {'price': 299.99}\n",
    "# update_all_matching_products(store, search_attributes, **update_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fcd0677-bcdd-45d7-9509-00f9e63d31c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:18:43.426050Z",
     "start_time": "2023-12-16T00:18:42.012340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             intent  \\\n",
      "0                 AddProductIntent1   \n",
      "1          UpdateProductByIdIntent2   \n",
      "2   UpdateProductByAttributeIntent3   \n",
      "3  UpdateAllMatchingProductsIntent4   \n",
      "4                FindProductIntent5   \n",
      "\n",
      "                                       sample_phrase  \n",
      "0           Add a new product named X with price $99  \n",
      "1       Change the price of product with ID X to $99  \n",
      "2  Update all products in category Electronics to...  \n",
      "3  Set all products from manufacturer X to price $99  \n",
      "4  Show me all products in the Home & Kitchen cat...  \n",
      "                              intent  \\\n",
      "0                  AddProductIntent1   \n",
      "1           UpdateProductByIdIntent2   \n",
      "2    UpdateProductByAttributeIntent3   \n",
      "3   UpdateAllMatchingProductsIntent4   \n",
      "4                 FindProductIntent5   \n",
      "5                  AddProductIntent1   \n",
      "6                  AddProductIntent1   \n",
      "7                  AddProductIntent1   \n",
      "8                  AddProductIntent1   \n",
      "9           UpdateProductByIdIntent2   \n",
      "10          UpdateProductByIdIntent2   \n",
      "11          UpdateProductByIdIntent2   \n",
      "12          UpdateProductByIdIntent2   \n",
      "13   UpdateProductByAttributeIntent3   \n",
      "14   UpdateProductByAttributeIntent3   \n",
      "15   UpdateProductByAttributeIntent3   \n",
      "16   UpdateProductByAttributeIntent3   \n",
      "17  UpdateAllMatchingProductsIntent4   \n",
      "18  UpdateAllMatchingProductsIntent4   \n",
      "19  UpdateAllMatchingProductsIntent4   \n",
      "20  UpdateAllMatchingProductsIntent4   \n",
      "21                FindProductIntent5   \n",
      "22                FindProductIntent5   \n",
      "23                FindProductIntent5   \n",
      "24                FindProductIntent5   \n",
      "\n",
      "                                        sample_phrase  \n",
      "0            Add a new product named X with price $99  \n",
      "1        Change the price of product with ID X to $99  \n",
      "2   Update all products in category Electronics to...  \n",
      "3   Set all products from manufacturer X to price $99  \n",
      "4   Show me all products in the Home & Kitchen cat...  \n",
      "5                  Insert a new item named Y for $150  \n",
      "6             Register product Z with a price of $200  \n",
      "7                     Include a new product W at $300  \n",
      "8                  List a new item Q for sale at $250  \n",
      "9             Alter the price of product ID Y to $150  \n",
      "10           Modify cost of product with ID Z to $200  \n",
      "11           Change the price of product ID W to $300  \n",
      "12           Adjust the price of product ID Q to $250  \n",
      "13    Mark all products in category Toys as available  \n",
      "14  Change availability of products in category Cl...  \n",
      "15     Set all items in category Gadgets to available  \n",
      "16  Update availability of products in category Books  \n",
      "17  Change all products by manufacturer Y to price...  \n",
      "18  Set price of all items from manufacturer Z to ...  \n",
      "19  Adjust price for all products by manufacturer ...  \n",
      "20  Update all items from manufacturer Q to cost $250  \n",
      "21       Display products in the Electronics category  \n",
      "22           Show all items in the Furniture category  \n",
      "23           List all products under Fashion category  \n",
      "24     Find items available in the Automotive section  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"intent\": [\"AddProductIntent1\", \"UpdateProductByIdIntent2\", \"UpdateProductByAttributeIntent3\", \"UpdateAllMatchingProductsIntent4\", \"FindProductIntent5\"],\n",
    "    \"sample_phrase\": [\n",
    "        \"Add a new product named X with price $99\",\n",
    "        \"Change the price of product with ID X to $99\",\n",
    "        \"Update all products in category Electronics to available\",\n",
    "        \"Set all products from manufacturer X to price $99\",\n",
    "        \"Show me all products in the Home & Kitchen category\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "intent_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(intent_df)\n",
    "\n",
    "# Additional sample phrases for each intent\n",
    "additional_data = {\n",
    "    \"AddProductIntent1\": [\n",
    "        \"Insert a new item named Y for $150\",\n",
    "        \"Register product Z with a price of $200\",\n",
    "        \"Include a new product W at $300\",\n",
    "        \"List a new item Q for sale at $250\"\n",
    "    ],\n",
    "    \"UpdateProductByIdIntent2\": [\n",
    "        \"Alter the price of product ID Y to $150\",\n",
    "        \"Modify cost of product with ID Z to $200\",\n",
    "        \"Change the price of product ID W to $300\",\n",
    "        \"Adjust the price of product ID Q to $250\"\n",
    "    ],\n",
    "    \"UpdateProductByAttributeIntent3\": [\n",
    "        \"Mark all products in category Toys as available\",\n",
    "        \"Change availability of products in category Clothes\",\n",
    "        \"Set all items in category Gadgets to available\",\n",
    "        \"Update availability of products in category Books\"\n",
    "    ],\n",
    "    \"UpdateAllMatchingProductsIntent4\": [\n",
    "        \"Change all products by manufacturer Y to price $150\",\n",
    "        \"Set price of all items from manufacturer Z to $200\",\n",
    "        \"Adjust price for all products by manufacturer W to $300\",\n",
    "        \"Update all items from manufacturer Q to cost $250\"\n",
    "    ],\n",
    "    \"FindProductIntent5\": [\n",
    "        \"Display products in the Electronics category\",\n",
    "        \"Show all items in the Furniture category\",\n",
    "        \"List all products under Fashion category\",\n",
    "        \"Find items available in the Automotive section\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame and concatenate it with the original DataFrame\n",
    "additional_phrases_df = pd.DataFrame([(intent, phrase) for intent, phrases in additional_data.items() for phrase in phrases], columns=['intent', 'sample_phrase'])\n",
    "intent_df = pd.concat([intent_df, additional_phrases_df], ignore_index=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(intent_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a8484bf-a9c9-47db-ab4b-3016b5ef37a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:23:25.015588Z",
     "start_time": "2023-12-16T00:21:02.761653Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 31s 31s/step - loss: 1.7161 - accuracy: 0.2000 - val_loss: 1.5720 - val_accuracy: 0.4000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.2853 - accuracy: 0.4000 - val_loss: 1.1967 - val_accuracy: 0.6000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.9699 - accuracy: 0.9500 - val_loss: 0.9973 - val_accuracy: 0.6000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7458 - accuracy: 1.0000 - val_loss: 0.8440 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5714 - accuracy: 1.0000 - val_loss: 0.7332 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4345 - accuracy: 1.0000 - val_loss: 0.6564 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2914 - accuracy: 1.0000 - val_loss: 0.5880 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.2384 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1668 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1251 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "# Encode the Intents\n",
    "label_encoder = LabelEncoder()\n",
    "intent_df['encoded_intent'] = label_encoder.fit_transform(intent_df['intent'])\n",
    "\n",
    "# Split data into train and validation sets\n",
    "train_df, val_df = train_test_split(intent_df, test_size=0.2)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_examples(df, limit=-1):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "\n",
    "    if limit > 0:\n",
    "        df = df.sample(limit)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        bert_input = tokenizer.encode_plus(row['sample_phrase'],\n",
    "                                           add_special_tokens=True,\n",
    "                                           max_length=64,\n",
    "                                           pad_to_max_length=True,\n",
    "                                           return_attention_mask=True,\n",
    "                                           return_token_type_ids=False)\n",
    "        input_ids.append(bert_input['input_ids'])\n",
    "        attention_masks.append(bert_input['attention_mask'])\n",
    "        labels.append(row['encoded_intent'])\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices(({'input_ids': input_ids, 'attention_masks': attention_masks}, labels))\n",
    "\n",
    "# Prepare the data\n",
    "train_data = encode_examples(train_df)\n",
    "val_data = encode_examples(val_df)\n",
    "\n",
    "# Build the model\n",
    "def build_model():\n",
    "    bert_encoder = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    input_ids = tf.keras.layers.Input(shape=(64,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_masks = tf.keras.layers.Input(shape=(64,), dtype=tf.int32, name=\"attention_masks\")\n",
    "\n",
    "    embedding = bert_encoder.bert(input_ids, attention_mask=attention_masks)[0]\n",
    "    out = tf.keras.layers.GlobalMaxPool1D()(embedding)\n",
    "    out = tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')(out)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, attention_masks], outputs=out)\n",
    "    model.compile(optimizer=Adam(learning_rate=3e-5), loss=SparseCategoricalCrossentropy(from_logits=True), metrics=[SparseCategoricalAccuracy('accuracy')])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data.shuffle(100).batch(32),\n",
    "                    epochs=10,\n",
    "                    validation_data=val_data.batch(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76aabbf3-4719-4e4c-a941-54863249bc25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:28:21.854321Z",
     "start_time": "2023-12-16T00:28:21.287633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 523ms/step - loss: 0.4850 - accuracy: 1.0000\n",
      "Validation Loss: 0.48504549264907837, Validation Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "val_loss, val_accuracy = model.evaluate(val_data.batch(32))\n",
    "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1631911e-f83c-4616-bb6a-f6f8eeb7d818",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:28:29.065057Z",
     "start_time": "2023-12-16T00:28:25.017652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "Predicted Intent for \"show me all products in the some category\": FindProductIntent5\n"
     ]
    }
   ],
   "source": [
    "def predict_intent(sample_phrase, model):\n",
    "    # Tokenize the sample phrase\n",
    "    bert_input = tokenizer.encode_plus(sample_phrase,\n",
    "                                       add_special_tokens=True,\n",
    "                                       max_length=64,\n",
    "                                       pad_to_max_length=True,\n",
    "                                       return_attention_mask=True,\n",
    "                                       return_token_type_ids=False)\n",
    "\n",
    "    input_ids = tf.constant([bert_input['input_ids']])\n",
    "    attention_masks = tf.constant([bert_input['attention_mask']])\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict({'input_ids': input_ids, 'attention_masks': attention_masks})\n",
    "\n",
    "    # Decode the prediction\n",
    "    intent_index = tf.argmax(prediction, axis=1).numpy()[0]\n",
    "    return label_encoder.inverse_transform([intent_index])[0]\n",
    "\n",
    "# Test the prediction function\n",
    "sample_phrase = \"show me all products in the some category\"\n",
    "predicted_intent = predict_intent(sample_phrase, model)\n",
    "print(f'Predicted Intent for \"{sample_phrase}\": {predicted_intent}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65f19b70-4a15-4ba3-ba91-3c07727aa761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:28:59.531803Z",
     "start_time": "2023-12-16T00:28:32.621135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/bert_bu_trained/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/bert_bu_trained/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('models/bert_bu_trained')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3f6c419-922a-4665-98fa-c1bb6b1b8e5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:32:29.995689Z",
     "start_time": "2023-12-16T00:32:11.580379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "Predicted Intent: FindProductIntent5\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('models/bert_bu_trained')\n",
    "\n",
    "sample_phrase = \"show all products in the some category\"\n",
    "predicted_intent = predict_intent(sample_phrase, loaded_model)\n",
    "print(f'Predicted Intent: {predicted_intent}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f00d26b8-0cc4-49dd-bc82-a21b2c83cd59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:36:52.493495Z",
     "start_time": "2023-12-16T00:36:50.155750Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "ner_model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d98f1acc-d3ba-4ece-9012-37dd7db1d31f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:36:55.690867Z",
     "start_time": "2023-12-16T00:36:55.641500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'Alter the price of product ID 10 to $150'\n",
      "Extracted Product ID: 10, Price: 150\n",
      "\n",
      "Sentence: 'Modify cost of product with ID 3 to $200'\n",
      "Extracted Product ID: 3, Price: 200\n",
      "\n",
      "Sentence: 'Change the price of product ID 45 to $300'\n",
      "Extracted Product ID: 45, Price: 300\n",
      "\n",
      "Sentence: 'Adjust the price of product ID 4 to $250'\n",
      "Extracted Product ID: 4, Price: 250\n"
     ]
    }
   ],
   "source": [
    "def extract_product_id_and_price(sentence):\n",
    "    doc = ner_model(sentence)\n",
    "    product_id = None\n",
    "    price = None\n",
    "\n",
    "    for token in doc:\n",
    "        # Extracting product ID\n",
    "        if token.lower_ == 'id':\n",
    "            next_token = doc[token.i + 1] if token.i + 1 < len(doc) else None\n",
    "            if next_token:\n",
    "                product_id = next_token.text\n",
    "\n",
    "        # Extracting price\n",
    "        if token.pos_ == 'NUM':\n",
    "            prev_token = doc[token.i - 1] if token.i > 0 else None\n",
    "            if prev_token and prev_token.text in ['$', 'to']:\n",
    "                price = token.text\n",
    "\n",
    "    return int(product_id), int(price)\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Alter the price of product ID 10 to $150\",\n",
    "    \"Modify cost of product with ID 3 to $200\",\n",
    "    \"Change the price of product ID 45 to $300\",\n",
    "    \"Adjust the price of product ID 4 to $250\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    product_id, price = extract_product_id_and_price(sentence)\n",
    "    print(f\"Sentence: '{sentence}'\\nExtracted Product ID: {product_id}, Price: {price}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3080301-84a3-4d81-8dbb-aec41eeede9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:36:59.873635Z",
     "start_time": "2023-12-16T00:36:59.834915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'Insert a new item named Y for $150'\n",
      "Extracted Product Name: Y, Price: 150\n",
      "\n",
      "Sentence: 'Register product Z with a price of $200'\n",
      "Extracted Product Name: Z, Price: 200\n",
      "\n",
      "Sentence: 'Include a new product W at $300'\n",
      "Extracted Product Name: W, Price: 300\n",
      "\n",
      "Sentence: 'List a new item Q for sale at $250'\n",
      "Extracted Product Name: Q, Price: 250\n",
      "\n",
      "Sentence: 'Register product nike with a price of 10000'\n",
      "Extracted Product Name: nike, Price: 10000\n"
     ]
    }
   ],
   "source": [
    "def extract_product_name_and_price(sentence):\n",
    "    doc = ner_model(sentence)\n",
    "    product_name = None\n",
    "    price = None\n",
    "\n",
    "    for token in doc:\n",
    "        # Extracting product name\n",
    "        if token.text.lower() in ['named', 'product', 'item']:\n",
    "            next_token = doc[token.i + 1] if token.i + 1 < len(doc) else None\n",
    "            if next_token:\n",
    "                # Adjust here: Accept any text as product name if it's not a common part of speech like preposition, conjunction, etc.\n",
    "                if next_token.pos_ not in ['ADP', 'CONJ', 'PUNCT', 'PRON', 'DET']:\n",
    "                    product_name = next_token.text\n",
    "\n",
    "        # Extracting price\n",
    "        if token.pos_ == 'NUM':\n",
    "            prev_tokens = [doc[i] for i in range(max(token.i - 4, 0), token.i)]\n",
    "            if any(t.text.lower() in ['$', 'for', 'at', 'price'] for t in prev_tokens):\n",
    "                price = token.text\n",
    "\n",
    "    return product_name, int(price)\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Insert a new item named Y for $150\",\n",
    "    \"Register product Z with a price of $200\",\n",
    "    \"Include a new product W at $300\",\n",
    "    \"List a new item Q for sale at $250\",\n",
    "    \"Register product nike with a price of 10000\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    product_name, price = extract_product_name_and_price(sentence)\n",
    "    print(f\"Sentence: '{sentence}'\\nExtracted Product Name: {product_name}, Price: {price}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd61dcd3-ac1d-47f7-a085-552b1a3e98eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:37:02.321499Z",
     "start_time": "2023-12-16T00:37:02.283925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'Mark all products in category Toys as available'\n",
      "Extracted Category: Toys, Availability: True\n",
      "\n",
      "Sentence: 'Change availability of products in category Clothes as not available'\n",
      "Extracted Category: Clothes, Availability: False\n",
      "\n",
      "Sentence: 'Set all items in category Gadgets to available'\n",
      "Extracted Category: Gadgets, Availability: True\n",
      "\n",
      "Sentence: 'Update availability of products in category Books to unavailable'\n",
      "Extracted Category: Books, Availability: False\n"
     ]
    }
   ],
   "source": [
    "def extract_category_and_availability(sentence):\n",
    "    doc = ner_model(sentence)\n",
    "    category = None\n",
    "    availability = None\n",
    "\n",
    "    for token in doc:\n",
    "        # Extracting category name\n",
    "        if token.text.lower() == 'category':\n",
    "            next_token = doc[token.i + 1] if token.i + 1 < len(doc) else None\n",
    "            if next_token and next_token.pos_ in ['NOUN', 'PROPN']:\n",
    "                category = next_token.text\n",
    "\n",
    "        # Extracting availability status\n",
    "        if token.text.lower() == 'available':\n",
    "            prev_token = doc[token.i - 1] if token.i > 0 else None\n",
    "            if prev_token and prev_token.text.lower() == 'not':\n",
    "                availability = False\n",
    "            else:\n",
    "                availability = True\n",
    "        elif token.text.lower() == 'unavailable':\n",
    "            availability = False\n",
    "\n",
    "    return category, availability\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Mark all products in category Toys as available\",\n",
    "    \"Change availability of products in category Clothes as not available\",\n",
    "    \"Set all items in category Gadgets to available\",\n",
    "    \"Update availability of products in category Books to unavailable\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    category, availability = extract_category_and_availability(sentence)\n",
    "    print(f\"Sentence: '{sentence}'\\nExtracted Category: {category}, Availability: {availability}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ced50f40-3b40-46ae-9fd6-6e2b14aa0f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:37:04.492444Z",
     "start_time": "2023-12-16T00:37:04.456265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'Change all products by manufacturer Y to price $150'\n",
      "Extracted Attributes: {'category': None, 'price': 150, 'quantity': None, 'color': None, 'size': None, 'rating': None, 'manufacturer': 'Y', 'availability': None}\n",
      "\n",
      "Sentence: 'Set price of all items from color Z to $200'\n",
      "Extracted Attributes: {'category': None, 'price': 200, 'quantity': None, 'color': 'Z', 'size': None, 'rating': None, 'manufacturer': None, 'availability': None}\n",
      "\n",
      "Sentence: 'Adjust price for all products by manufacturer W to $300'\n",
      "Extracted Attributes: {'category': None, 'price': None, 'quantity': None, 'color': None, 'size': None, 'rating': None, 'manufacturer': 'W', 'availability': None}\n",
      "\n",
      "Sentence: 'Update all items from manufacturer Q to cost $250'\n",
      "Extracted Attributes: {'category': None, 'price': 250, 'quantity': None, 'color': None, 'size': None, 'rating': None, 'manufacturer': 'Q', 'availability': None}\n"
     ]
    }
   ],
   "source": [
    "def extract_product_attributes(sentence):\n",
    "    doc = ner_model(sentence)\n",
    "    attributes = {\n",
    "        \"category\": None,\n",
    "        \"price\": None,\n",
    "        \"quantity\": None,\n",
    "        \"color\": None,\n",
    "        \"size\": None,\n",
    "        \"rating\": None,\n",
    "        \"manufacturer\": None,\n",
    "        \"availability\": None\n",
    "    }\n",
    "\n",
    "    for token in doc:\n",
    "        # Check for attribute names in the sentence\n",
    "        if token.text.lower() in attributes:\n",
    "            next_token = doc[token.i + 1] if token.i + 1 < len(doc) else None\n",
    "            if next_token and next_token.pos_ in ['NOUN', 'PROPN', 'NUM']:\n",
    "                attributes[token.text.lower()] = next_token.text\n",
    "\n",
    "        # Extracting price specifically\n",
    "        if token.pos_ == 'NUM' and (token.head.text.lower() in ['price', 'cost'] or (token.head.head and token.head.head.text.lower() in ['price', 'cost'])):\n",
    "            attributes['price'] = int(token.text)\n",
    "\n",
    "    return attributes\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Change all products by manufacturer Y to price $150\",\n",
    "    \"Set price of all items from color Z to $200\",\n",
    "    \"Adjust price for all products by manufacturer W to $300\",\n",
    "    \"Update all items from manufacturer Q to cost $250\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    extracted_attributes = extract_product_attributes(sentence)\n",
    "    print(f\"Sentence: '{sentence}'\\nExtracted Attributes: {extracted_attributes}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1042e10d-300a-460d-b0cb-b7e13017452d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:37:08.441801Z",
     "start_time": "2023-12-16T00:37:08.406545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'Display products in the Electronics category'\n",
      "Extracted Category: Electronics\n",
      "\n",
      "Sentence: 'Show all items in the Furniture category'\n",
      "Extracted Category: Furniture\n",
      "\n",
      "Sentence: 'List all products under Fashion category'\n",
      "Extracted Category: Fashion\n",
      "\n",
      "Sentence: 'Find items available in the Automotive section'\n",
      "Extracted Category: Automotive\n"
     ]
    }
   ],
   "source": [
    "def extract_category_for_find_intent(sentence):\n",
    "    doc = ner_model(sentence)\n",
    "    category = None\n",
    "\n",
    "    for token in doc:\n",
    "        # Check if the token is a preposition commonly used before category names\n",
    "        if token.text.lower() in ['in', 'under', 'section']:\n",
    "            # Look ahead to find a noun or proper noun that could be the category\n",
    "            for next_token in doc[token.i+1:]:\n",
    "                if next_token.pos_ in ['NOUN', 'PROPN']:\n",
    "                    # Check if this noun is followed by 'category' or 'section'\n",
    "                    if next_token.nbor(1).text.lower() in ['category', 'section']:\n",
    "                        category = next_token.text\n",
    "                    break\n",
    "\n",
    "    return category\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Display products in the Electronics category\",\n",
    "    \"Show all items in the Furniture category\",\n",
    "    \"List all products under Fashion category\",\n",
    "    \"Find items available in the Automotive section\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    category = extract_category_for_find_intent(sentence)\n",
    "    print(f\"Sentence: '{sentence}'\\nExtracted Category: {category}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf010ccc-3756-4735-99c9-d6cf6acb1bb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:37:10.858662Z",
     "start_time": "2023-12-16T00:37:10.840650Z"
    }
   },
   "outputs": [],
   "source": [
    "store = Store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "549468a4-21cd-43e9-ae8b-030423f3c153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:37:13.645638Z",
     "start_time": "2023-12-16T00:37:13.587297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0ef2ceae1d42d4b90059f737c8fee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Chat for help', placeholder='Interact for help managing the inventory')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc65497e744746738302fb35c33cc6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae21b6ce4624c359440ef660bbf5687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def store_method_for_intent(intent, sentence):\n",
    "    if intent == \"AddProductIntent1\":\n",
    "        product_name, price = extract_product_name_and_price(sentence)\n",
    "        if product_name is None or price is None:\n",
    "            print(\"Could not extract product name and price. Please try again.\")\n",
    "            return\n",
    "        id = len(store.products) + 1\n",
    "        product = Product(id=int(id), name=product_name, price=price, category='', quantity=0, \n",
    "                          color='', size='', rating=0, manufacturer='', availability=True, description='')\n",
    "        store.add_product(product)\n",
    "        print(\"Product added:\", product.to_json())\n",
    "    elif intent == \"UpdateProductByIdIntent2\":\n",
    "        id, price = extract_product_id_and_price(sentence)\n",
    "        if id is None or price is None:\n",
    "            print(\"Could not extract product ID and price. Please try again.\")\n",
    "            return\n",
    "        store.update_product(product_id=id, price=price)\n",
    "        print(\"Product updated:\", store.get_product(id).to_json())\n",
    "    elif intent == \"UpdateProductByAttributeIntent3\":\n",
    "        category, availability = extract_category_and_availability(sentence)\n",
    "        if category is None:\n",
    "            print(\"Could not extract category. Please try again.\")\n",
    "            return\n",
    "        store.update_products_by_category(category, availability)\n",
    "    elif intent == \"FindProductIntent5\":\n",
    "        category = extract_category_for_find_intent(sentence)\n",
    "        if category is None:\n",
    "            print(\"Could not extract category. Please try again.\")\n",
    "            return\n",
    "        print(f\"Displaying products in category: {category}\")\n",
    "        store.display_products_by_category(category)\n",
    "\n",
    "    else:\n",
    "        print(f\"No action for intent: {intent}\")\n",
    "\n",
    "# UI Widget setup\n",
    "text = widgets.Text(description='Chat for help', placeholder='Interact for help managing the inventory')\n",
    "button = widgets.Button(description=\"Process\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        sentence = text.value\n",
    "        predicted_intent = predict_intent(sentence, loaded_model)\n",
    "        store_method_for_intent(predicted_intent, sentence)\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "display(text, button, output)\n",
    "# Display products in the Electronics ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1396269d-5bb3-45e2-af60-3dc66acc9b93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:39:48.114699Z",
     "start_time": "2023-12-16T00:39:48.107710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Clothing\",\n",
      "    \"color\": \"OldLace\",\n",
      "    \"description\": \"Anyone far become worker defense research rock but. Action part election measure bar support special.\\nBenefit week audience home catch magazine. Buy but notice fill also.\",\n",
      "    \"id\": \"f4f68fcf-33cf-4f7f-a184-a5936234083a\",\n",
      "    \"manufacturer\": \"Lambert-Smith\",\n",
      "    \"name\": \"Responsibility Max\",\n",
      "    \"price\": 393.0,\n",
      "    \"quantity\": 14,\n",
      "    \"rating\": 4.3,\n",
      "    \"size\": \"Large\"\n",
      "}\n",
      "{\n",
      "    \"availability\": true,\n",
      "    \"category\": \"Home & Kitchen\",\n",
      "    \"color\": \"SteelBlue\",\n",
      "    \"description\": \"Necessary either consider. Cover occur drop woman.\\nTelevision himself easy worry training. Year better central fine. Such price base itself.\",\n",
      "    \"id\": \"ab86dadf-4df2-4a70-addd-9a6acf29811d\",\n",
      "    \"manufacturer\": \"Richards, Cantu and Vargas\",\n",
      "    \"name\": \"Change Plus\",\n",
      "    \"price\": 686.93,\n",
      "    \"quantity\": 23,\n",
      "    \"rating\": 2.8,\n",
      "    \"size\": \"Medium\"\n",
      "}\n",
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Home & Kitchen\",\n",
      "    \"color\": \"Silver\",\n",
      "    \"description\": \"Better capital white really minute people eat. Risk four fly writer both reflect generation. Anything plant per high small trouble.\",\n",
      "    \"id\": \"46bd81ff-6cc8-41f7-a657-3a5e4399482f\",\n",
      "    \"manufacturer\": \"Evans, Norman and Logan\",\n",
      "    \"name\": \"Soldier Max\",\n",
      "    \"price\": 500.9,\n",
      "    \"quantity\": 3,\n",
      "    \"rating\": 4.9,\n",
      "    \"size\": \"Medium\"\n",
      "}\n",
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Home & Kitchen\",\n",
      "    \"color\": \"Aqua\",\n",
      "    \"description\": \"Kind eye everybody reveal their town order follow.\\nDecade hear able floor scientist fast read. Everything detail unit staff music environment skill finish. Production it field rate source peace.\",\n",
      "    \"id\": \"3abe322d-4b74-432e-9e4e-c371d98f0d17\",\n",
      "    \"manufacturer\": \"Taylor, Harris and Gregory\",\n",
      "    \"name\": \"Industry Pro\",\n",
      "    \"price\": 914.85,\n",
      "    \"quantity\": 22,\n",
      "    \"rating\": 3.6,\n",
      "    \"size\": \"Medium\"\n",
      "}\n",
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Clothing\",\n",
      "    \"color\": \"Chartreuse\",\n",
      "    \"description\": \"Thought season rate cost enter together experience. Our control determine situation nearly.\",\n",
      "    \"id\": \"6e04bbf5-165f-455f-8981-70df20618651\",\n",
      "    \"manufacturer\": \"Allen LLC\",\n",
      "    \"name\": \"Tree Plus\",\n",
      "    \"price\": 742.75,\n",
      "    \"quantity\": 38,\n",
      "    \"rating\": 2.0,\n",
      "    \"size\": \"Small\"\n",
      "}\n",
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Electronics\",\n",
      "    \"color\": \"GoldenRod\",\n",
      "    \"description\": \"Party laugh job very customer will require. Project girl compare bad inside enough father. Garden blood each plant majority.\",\n",
      "    \"id\": \"104f1b3d-100e-4eb3-9b5e-dec754a2a9ac\",\n",
      "    \"manufacturer\": \"Harrison PLC\",\n",
      "    \"name\": \"Hour Plus\",\n",
      "    \"price\": 450.5,\n",
      "    \"quantity\": 56,\n",
      "    \"rating\": 1.8,\n",
      "    \"size\": \"Medium\"\n",
      "}\n",
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Home & Kitchen\",\n",
      "    \"color\": \"HotPink\",\n",
      "    \"description\": \"Red same light determine player. Stay increase question ahead majority begin sure myself.\\nAssume local receive thus head. Ok bag part. Race front performance south.\",\n",
      "    \"id\": \"11243742-f346-47e2-8e7e-4d01fd480472\",\n",
      "    \"manufacturer\": \"Garrett, Small and Castro\",\n",
      "    \"name\": \"Authority Max\",\n",
      "    \"price\": 731.06,\n",
      "    \"quantity\": 19,\n",
      "    \"rating\": 3.6,\n",
      "    \"size\": \"Medium\"\n",
      "}\n",
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Electronics\",\n",
      "    \"color\": \"LimeGreen\",\n",
      "    \"description\": \"Pretty simple month agency difficult often light. Case decision anyone wind wrong sure. Check democratic significant something side without.\\nEnter form move toward four. Watch physical general.\",\n",
      "    \"id\": \"7b3e55a0-9671-4e85-a2e3-9fb19c559db2\",\n",
      "    \"manufacturer\": \"Hensley-West\",\n",
      "    \"name\": \"Each Plus\",\n",
      "    \"price\": 521.34,\n",
      "    \"quantity\": 51,\n",
      "    \"rating\": 1.8,\n",
      "    \"size\": \"Medium\"\n",
      "}\n",
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Home & Kitchen\",\n",
      "    \"color\": \"HoneyDew\",\n",
      "    \"description\": \"Truth animal should. Strong none street rule specific decision.\\nBar executive foreign set. View see hit no watch more.\\nWonder development thought receive. Maybe safe throughout remain.\",\n",
      "    \"id\": \"e65cf14a-e55b-4cf3-a95a-8aefbb2ab81f\",\n",
      "    \"manufacturer\": \"Anderson, Carroll and Baker\",\n",
      "    \"name\": \"Process Max\",\n",
      "    \"price\": 94.91,\n",
      "    \"quantity\": 30,\n",
      "    \"rating\": 2.0,\n",
      "    \"size\": \"Small\"\n",
      "}\n",
      "{\n",
      "    \"availability\": false,\n",
      "    \"category\": \"Electronics\",\n",
      "    \"color\": \"Bisque\",\n",
      "    \"description\": \"Admit tend collection line court. Imagine family beautiful should inside admit. Science explain bag real.\\nLate son local kid. Happen yes enough cultural cup than range road.\",\n",
      "    \"id\": \"f4a09f02-1ab4-41a4-a690-09e82b5a6f06\",\n",
      "    \"manufacturer\": \"Moore Ltd\",\n",
      "    \"name\": \"Name Pro\",\n",
      "    \"price\": 487.14,\n",
      "    \"quantity\": 84,\n",
      "    \"rating\": 3.6,\n",
      "    \"size\": \"Medium\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "store.display_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138de49de77973d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
